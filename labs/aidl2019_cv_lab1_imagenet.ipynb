{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aidl2019_cv_lab1_imagenet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "whkJ-A2tJ2wp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ImageNet Classification\n",
        "## Created by [Daniel Fojo](https://www.linkedin.com/in/daniel-fojo/) and [Janna Escur](https://www.linkedin.com/in/janna-escur-i-gelabert-276b1212b/?originalSubdomain=es) \n",
        "##[Postgraduate Course on Artificial Intelligence with Deep Learning](https://www.talent.upc.edu/ing/estudis/formacio/curs/310400/postgrau-artificial-intelligence-deep-learning/). \n",
        "\n",
        "We will first train a network to classify MNIST to get familiarized with PyTorch's syntax.\n",
        "\n",
        "\n",
        "First, we define our neural network. In PyTorch,  NN are just Python classes that inherit from nn.Module. We declare all the layers that we are going to use in the constructor (init method), and then define how we should do the forward pass in the `forward` method. The `backward` method is done automatically, so we do not need to code it."
      ]
    },
    {
      "metadata": {
        "id": "dccBkXlGJ0cP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imshow\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"You should enable GPU runtime!!\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1HDP96I8J5GQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=5, stride=1)\n",
        "        self.fc1 = nn.Linear(in_features=4*4*50, out_features=500)\n",
        "        self.fc2 = nn.Linear(in_features=500, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(x.size(0), -1)  # Flatten while keeping the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.log_softmax(self.fc2(x), dim=1)\n",
        "        return x\n",
        "   \n",
        "\n",
        "model = Net().to(device)  # Move model to GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uwqCOAjRMMmj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now define the dataloaders that will feed the data to our NN during trainig in batches. The `dataset` class `torchvision.dataset.MNIST` already has the MNIST dataset loaded. We could add data augmentation here."
      ]
    },
    {
      "metadata": {
        "id": "ML4eZvn6LfUN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(\"data/MNIST\", train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),  # Here we could add extra data augmentation\n",
        "                       transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                   ]))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(\"data/MNIST\", train=False, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                   ]))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6CLRWn16Nd_B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For our optimizer, we will use SGD, and it will optimize the parameters of our model. For our loss, we wil use Negative Log Likelihood (together with the log_softmax of the last layer it is equivalent to the Cross Entropy while being more numerically stable)."
      ]
    },
    {
      "metadata": {
        "id": "smkdIjhyNjBO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RHBh_gSey_qD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will define a custom metric to monitor during training."
      ]
    },
    {
      "metadata": {
        "id": "ZFmXK1vboUkU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(preds, y):\n",
        "    preds = preds.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "    correct = preds.eq(y.view_as(preds)).sum().item()\n",
        "    return correct/preds.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dBfhfPz0zHDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here, we do our training. At each step we do a forward pass of our input, we compute the gradients and we do an optimizer step. At the end of each epoch we also compute metrics with our validation dataset."
      ]
    },
    {
      "metadata": {
        "id": "H0RR98YyN5DK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Train mode\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()  # Reset gradients from last step\n",
        "        preds = model(x)  # Forward pass\n",
        "        loss = criterion(preds, y)\n",
        "        loss.backward()  # Compute gradients\n",
        "        optimizer.step()  # Do an optimizer step\n",
        "        if i%20 == 0:\n",
        "            print(f\"TRAIN Epoch {epoch}: [{i}/{len(train_loader)}] Loss: {loss.item():.4f}; Accuracy: {accuracy(preds, y)}\")\n",
        "        \n",
        "    \n",
        "    model.eval()  # Test mode\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds = model(x)\n",
        "        loss = criterion(preds, y)\n",
        "        if i%20 == 0:\n",
        "            print(f\"TEST Epoch {epoch}: [{i}/{len(test_loader)}] Loss: {loss.item():.4f}; Accuracy: {accuracy(preds, y)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZGd1h2JxpKc9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercice 1: train with CIFAR10\n",
        "\n",
        "You should complete the following code to train a network with CIFAR10.\n",
        "\n",
        "If you want, you can try to add data augmentation, dropout and weight decay to regularize the model."
      ]
    },
    {
      "metadata": {
        "id": "jSNBwCafpSTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = \n",
        "        self.conv2 = \n",
        "        self.fc1 = \n",
        "        self.fc2 = \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return x\n",
        "   \n",
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "\n",
        "train_dataset = datasets.CIFAR10(\"data/CIFAR10\", train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),  # Here we could add extra data augmentation\n",
        "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                   ]))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(\"data/CIFAR10\", train=False, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                   ]))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Train mode\n",
        "    for i, (x, y) in enumerate(train_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()  # Reset gradients from last step\n",
        "        preds = model(x)  # Forward pass\n",
        "        loss = criterion(preds, y)\n",
        "        loss.backward()  # Compute gradients\n",
        "        optimizer.step()  # Do an optimizer step\n",
        "        if i%20 == 0:\n",
        "            print(f\"TRAIN Epoch {epoch}: [{i}/{len(train_loader)}] Loss: {loss.item():.4f}; Accuracy: {accuracy(preds, y)}\")\n",
        "        \n",
        "    \n",
        "    model.eval()  # Test mode\n",
        "    for i, (x, y) in enumerate(test_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds = model(x)\n",
        "        loss = criterion(preds, y)\n",
        "        if i%20 == 0:\n",
        "            print(f\"TEST Epoch {epoch}: [{i}/{len(test_loader)}] Loss: {loss.item():.4f}; Accuracy: {accuracy(preds, y)}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TE2AORG9qk7F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pretrained imagenet models"
      ]
    },
    {
      "metadata": {
        "id": "2SVCtmKgqwzr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In both PyTorch and Keras there are many models pretrained with Imagenet. You can see the lists here: https://pytorch.org/docs/stable/torchvision/models.html \n",
        "and https://keras.io/applications/.\n",
        "We will see how to use a pretrained VGG16 from PyTorch to predict images taken from the internet.\n"
      ]
    },
    {
      "metadata": {
        "id": "d9q34b-Vzqus",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We first declare our model with `pretrained=True`, which will download the pretrained weights."
      ]
    },
    {
      "metadata": {
        "id": "4-VCYnjZrDH_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "model = models.vgg16(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "60paNsDSz1CW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also load the 1000 imagenet labels in a Python dictionary."
      ]
    },
    {
      "metadata": {
        "id": "O8WjfmuD-aI1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import ast\n",
        "urllib.request.urlretrieve(\"https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt\", \"labels.json\")\n",
        "with open(\"labels.json\") as f:\n",
        "    labels = ast.literal_eval(f.read())\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36qxc1rD0CnQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now download a sample image to test our network."
      ]
    },
    {
      "metadata": {
        "id": "EaWQV0VN3w34",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "from PIL import Image\n",
        "urllib.request.urlretrieve(\"https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/hires/2018/2-dog.jpg\", \"image.jpg\")\n",
        "%ls\n",
        "pil_image = Image.open(\"image.jpg\")\n",
        "imshow(np.asarray(pil_image))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UGjzIncp0PVx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We should do some preprocessing before feeding the image to our network. The following transformations are the same that were used when training with Imagenet. Note that we have to add a batch dimension at the beginning, even if we are feeding just one image to the network."
      ]
    },
    {
      "metadata": {
        "id": "NIyT1s1a4Bca",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "torch_image = preprocess(pil_image)\n",
        "torch_image = torch_image.unsqueeze(0)  # Add batch dimension\n",
        "print(\"Image shape: \", torch_image.shape)\n",
        "print(\"Image values: \", torch_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P4xNWAHO1Dry",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can get the predictions of our network. Note that a network trained with imagenet will have 1000 outputs. Here we only show the top 3 predictions and their probabilities."
      ]
    },
    {
      "metadata": {
        "id": "fP7roGFn7WTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output = model(torch_image)\n",
        "print(\"Output shape: \", output.shape)\n",
        "probs, idxs = output.topk(3)\n",
        "print(probs[0])\n",
        "print([labels[idx.item()] for idx in idxs[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RDYhmZ9rEl2V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Exercice 2\n",
        "Do the prediction with other images using different networks and compare the results.  You can use the function following function predict_from_url. The list of pretrained PyTorch networks can be found here https://pytorch.org/docs/stable/torchvision/models.html "
      ]
    },
    {
      "metadata": {
        "id": "ciX-8naSEzpz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_from_url(url, model):\n",
        "    urllib.request.urlretrieve(url, \"image.jpg\")\n",
        "    pil_image = Image.open(\"image.jpg\")\n",
        "    imshow(np.asarray(pil_image))\n",
        "    torch_image = preprocess(pil_image).unsqueeze(0)\n",
        "    output = model(torch_image)\n",
        "    probs, idxs = output.topk(3)\n",
        "    print(probs[0])\n",
        "    print([labels[idx.item()] for idx in idxs[0]])\n",
        "\n",
        "predict_from_url(\"https://img.purch.com/h/1400/aHR0cDovL3d3dy5saXZlc2NpZW5jZS5jb20vaW1hZ2VzL2kvMDAwLzEwMi8xNjIvb3JpZ2luYWwvYmVlci1hbmQtd2hlYXQuanBn\", model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXjwnckj1tEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}